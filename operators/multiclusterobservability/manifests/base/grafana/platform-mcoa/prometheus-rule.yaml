apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  creationTimestamp: null
  labels:
    app.kubernetes.io/component: platform-metrics-collector
    app.kubernetes.io/part-of: multicluster-observability-addon
    app.kubernetes.io/managed-by: multicluster-observability-operator
  name: platform-rules-default
  namespace: open-cluster-management-observability
spec:
  groups:
  - name: acm-platform-default-rules
    rules:
    - expr: sum(node_memory_MemAvailable_bytes{job="node-exporter"} or (node_memory_Buffers_bytes{job="node-exporter"}
        + node_memory_Cached_bytes{job="node-exporter"} + node_memory_MemFree_bytes{job="node-exporter"}
        + node_memory_Slab_bytes{job="node-exporter"}))
      record: :node_memory_MemAvailable_bytes:sum
    - expr: sum(grpc_server_started_total{job="etcd",grpc_service="etcdserverpb.Lease",grpc_type="bidi_stream"})
        - sum(grpc_server_handled_total{job="etcd",grpc_service="etcdserverpb.Lease",grpc_type="bidi_stream"})
      record: active_streams_lease:grpc_server_handled_total:sum
    - expr: sum(grpc_server_started_total{job="etcd",grpc_service="etcdserverpb.Watch",grpc_type="bidi_stream"})
        - sum(grpc_server_handled_total{job="etcd",grpc_service="etcdserverpb.Watch",grpc_type="bidi_stream"})
      record: active_streams_watch:grpc_server_handled_total:sum
    - expr: (histogram_quantile(0.99,sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",
        verb!="WATCH"}[5m])) by (le)))
      record: apiserver_request_duration_seconds:histogram_quantile_99
    - expr: (histogram_quantile(0.99,sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",
        verb!="WATCH"}[5m])) by (le, verb, instance)))
      record: apiserver_request_duration_seconds:histogram_quantile_99:instance
    - expr: sum(machine_memory_bytes)
      record: cluster:machine_memory:sum
    - expr: sum(sum(sum(kube_pod_container_resource_requests{resource="cpu",unit="core"}) by (pod,namespace,container)
        * on(pod,namespace) group_left(phase) max(kube_pod_status_phase{phase=~"Running|Pending|Unknown"}
        >0) by (pod,namespace,phase)) by (pod,namespace,phase))
      record: cluster:kube_pod_container_resource_requests:cpu:sum
    - expr: sum(sum(sum(kube_pod_container_resource_requests{resource="memory",unit="byte"}) by (pod,namespace,container)
        * on(pod,namespace) group_left(phase) max(kube_pod_status_phase{phase=~"Running|Pending|Unknown"}
        >0) by (pod,namespace,phase)) by (pod,namespace,phase))
      record: cluster:kube_pod_container_resource_requests:memory:sum
    - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait",mode!="steal"}[5m])) / count(sum(node_cpu_seconds_total)
        BY (instance, cpu))
      record: cluster:node_cpu:ratio  
    - expr: |
        1 - avg without (cpu, mode) (
          rate(node_cpu_seconds_total{job="node-exporter", mode="idle"}[1m])
        )
      record: instance:node_cpu_utilisation:rate1m
    - expr: |
        (
          node_load1{job="node-exporter"}
        /
          instance:node_num_cpu:sum{job="node-exporter"}
        )
      record: instance:node_load1_per_cpu:ratio
    - expr: |
        1 - (
          node_memory_MemAvailable_bytes{job="node-exporter"}
        /
          node_memory_MemTotal_bytes{job="node-exporter"}
        )
      record: instance:node_memory_utilisation:ratio
    - expr: |
        sum without (device) (
          rate(node_network_receive_bytes_total{job="node-exporter", device!="lo"}[1m])
        )
      record: instance:node_network_receive_bytes_excluding_lo:rate1m
    - expr: |
        sum without (device) (
          rate(node_network_receive_drop_total{job="node-exporter", device!="lo"}[1m])
        )
      record: instance:node_network_receive_drop_excluding_lo:rate1m
    - expr: |
        sum without (device) (
          rate(node_network_transmit_bytes_total{job="node-exporter", device!="lo"}[1m])
        )
      record: instance:node_network_transmit_bytes_excluding_lo:rate1m
    - expr: |
        sum without (device) (
          rate(node_network_transmit_drop_total{job="node-exporter", device!="lo"}[1m])
        )
      record: instance:node_network_transmit_drop_excluding_lo:rate1m
    - expr: |
        count without (cpu) (
          count without (mode) (
            node_cpu_seconds_total{job="node-exporter"}
          )
        )
      record: instance:node_num_cpu:sum
    - expr: |
        rate(node_vmstat_pgmajfault{job="node-exporter"}[1m])
      record: instance:node_vmstat_pgmajfault:rate1m
    - expr: |
        rate(node_disk_io_time_seconds_total{job="node-exporter", device=~"mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+"}[1m])
      record: instance_device:node_disk_io_time_seconds:rate1m
    - expr: |
        rate(node_disk_io_time_weighted_seconds_total{job="node-exporter", device=~"mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+"}[1m])
      record: instance_device:node_disk_io_time_weighted_seconds:rate1m
    - expr: |-
        max by (cluster, namespace, workload, pod) (
          label_replace(
            label_replace(
              kube_pod_owner{job="kube-state-metrics", owner_kind="ReplicaSet"},
              "replicaset", "$1", "owner_name", "(.*)"
            ) * on(replicaset, namespace) group_left(owner_name) topk by(replicaset, namespace) (
              1, max by (replicaset, namespace, owner_name) (
                kube_replicaset_owner{job="kube-state-metrics"}
              )
            ),
            "workload", "$1", "owner_name", "(.*)"
          )
        )
      labels:
        workload_type: deployment
      record: namespace_workload_pod:kube_pod_owner:relabel
    - expr: |-
        max by (cluster, namespace, workload, pod) (
          label_replace(
            kube_pod_owner{job="kube-state-metrics", owner_kind="DaemonSet"},
            "workload", "$1", "owner_name", "(.*)"
          )
        )
      labels:
        workload_type: daemonset
      record: namespace_workload_pod:kube_pod_owner:relabel
    - expr: |-
        max by (cluster, namespace, workload, pod) (
          label_replace(
            kube_pod_owner{job="kube-state-metrics", owner_kind="StatefulSet"},
            "workload", "$1", "owner_name", "(.*)"
          )
        )
      labels:
        workload_type: statefulset
      record: namespace_workload_pod:kube_pod_owner:relabel
    - record: namespace_workload_pod:kube_pod_owner:relabel:avg
      expr: count(avg(namespace_workload_pod:kube_pod_owner:relabel{pod!=""}) by (workload, namespace)) by (namespace)
    - record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum
      expr: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{container!=""}) by (namespace) or sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate{container!=""}) by (namespace)
    - expr: sum(rate(grpc_server_handled_total{job="etcd",grpc_type="unary",grpc_code!="OK"}[5m]))
      record: rpc_rate:grpc_server_handled_total:sum_rate
    - expr: sum(increase(apiserver_request_duration_seconds_bucket{job="apiserver",service="kubernetes",le="1",verb=~"POST|PUT|DELETE|PATCH"}[1m]))
        / sum(increase(apiserver_request_duration_seconds_bucket{job="apiserver",service="kubernetes",verb=~"POST|PUT|DELETE|PATCH"}[1m]))
      record: sli:apiserver_request_duration_seconds:trend:1m
    - expr: sli:apiserver_request_duration_seconds:trend:1m >= bool 0.9900
      record: sli:apiserver_request_duration_seconds:bin:trend:1m
    - expr: sum(rate(apiserver_request_total{job="apiserver"}[1h])) by (code, instance)
      record: sum:apiserver_request_total:1h
    - expr: sum(rate(apiserver_request_total{job="apiserver"}[5m])) by (code, instance)
      record: sum:apiserver_request_total:5m
    - record: kube_pod_container_resource_limits:sum
      expr: sum(kube_pod_container_resource_limits) by (resource, namespace)
    - expr: |-
        sum by (cluster, namespace, pod, container) (
          rate(container_cpu_usage_seconds_total{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}[5m])
        ) * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (
          1, max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
        )
      record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate
    - expr: histogram_quantile(0.99, sum(rate(workqueue_queue_duration_seconds_bucket{job="apiserver"}[5m])) by (instance, name, le))
      record: workqueue_queue_duration_seconds_bucket:apiserver:histogram_quantile_99
    - expr: sum(rate(grpc_server_started_total{job="etcd",grpc_type="unary"}[5m]))
      record: grpc_server_started_total:etcd_unary:sum_rate
    - expr: avg(rate(node_cpu_seconds_total{mode="idle"}[5m]))
      record: node_cpu_seconds_total:mode_idle:avg_rate5m
    - expr: sum(cluster:kube_pod_container_resource_requests:memory:sum) by (cluster) / sum(kube_node_status_allocatable{resource="memory"}) by (cluster)
      record: cluster:memory_requested:ratio
    - expr: 1 - sum(:node_memory_MemAvailable_bytes:sum) by (cluster) / sum(kube_node_status_allocatable{resource="memory"}) by (cluster)
      record: cluster:memory_utilized:ratio
    - expr: sum(kube_node_status_allocatable{resource="cpu"}) by (cluster)
      record: cluster:cpu_allocatable:sum
    - expr: sum(cluster:kube_pod_container_resource_requests:cpu:sum) by (cluster) / sum(kube_node_status_allocatable{resource="cpu"}) by (cluster)
      record: cluster:cpu_requested:ratio
    - expr: sum(machine_cpu_cores) by (cluster)
      record: cluster:cpu_cores:sum
    - record: namespace_pod:container_network_receive_bytes_total:sum
      expr: sum(irate(container_network_receive_bytes_total[5m])) by (namespace, pod)
    - record: namespace_pod:container_network_receive_packets_total:sum
      expr: sum(irate(container_network_receive_packets_total[5m])) by (namespace, pod)
    - record: namespace_pod:container_network_receive_packets_dropped_total:sum
      expr: sum(irate(container_network_receive_packets_dropped_total[5m])) by (namespace, pod)
    - record: namespace_pod:container_network_transmit_packets_total:sum
      expr: sum(irate(container_network_transmit_packets_total[5m])) by (namespace, pod)
    - record: namespace_pod:container_network_transmit_bytes_total:sum
      expr: sum(irate(container_network_transmit_bytes_total[5m])) by (namespace, pod)
    - record: namespace_pod:container_network_transmit_packets_dropped_total:sum
      expr: sum(irate(container_network_transmit_packets_dropped_total[5m])) by (namespace, pod)
  - name: kubernetes-storage
    rules:
      - alert: KubePersistentVolumeFillingUp1Min
        annotations:
          summary: PersistentVolume is filling up.
          description: "The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} is only {{ $value | humanizePercentage }} free."
        expr: kubelet_volume_stats_available_bytes{namespace="open-cluster-management-observability"}/kubelet_volume_stats_capacity_bytes{namespace="open-cluster-management-observability"} < 0.03
        for: 1m
        labels:
          instance: "{{ $labels.instance }}"
          cluster: "{{ $labels.cluster }}"
          clusterID: "{{ $labels.clusterID }}"
          PersistentVolumeClaim: "{{ $labels.persistentvolumeclaim }}"
          severity: info
      - alert: KubePersistentVolumeFillingUp1Hour
        annotations:
          summary: PersistentVolume is filling up and is predicted to run out of space in 6h.
          description: "The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} is only {{ $value | humanizePercentage }} free."
        expr: (kubelet_volume_stats_available_bytes{namespace="open-cluster-management-observability"}/kubelet_volume_stats_capacity_bytes{namespace="open-cluster-management-observability"}) < 0.15 and (predict_linear(kubelet_volume_stats_available_bytes{namespace="open-cluster-management-observability"}[6h], 4 * 24 * 3600)) <0
        for: 1h
        labels:
          instance: "{{ $labels.instance }}"
          cluster: "{{ $labels.cluster }}"
          clusterID: "{{ $labels.clusterID }}"
          PersistentVolumeClaim: "{{ $labels.persistentvolumeclaim }}"
          severity: info
  - name: policy-reports
    rules:
      - alert: ViolatedPolicyReport
        annotations:
          summary: "There is a policy report violation with a {{ $labels.severity }} severity level detected."
          description: "The policy: {{ $labels.policy }} has a severity of {{ $labels.severity }} on cluster: {{ $labels.cluster }}"
        expr: sum without (managed_cluster_id) (label_replace((sum without (clusterID) (label_replace((sum(policyreport_info * on (managed_cluster_id) group_left (cluster) label_replace(acm_managed_cluster_labels, "cluster", "$1", "name", "(.*)")) by (cluster, category, clusterID, managed_cluster_id, policy, severity) > 0),"hub_cluster_id", "$1", "clusterID", "(.*)"))),"clusterID", "$1", "managed_cluster_id", "(.*)"))
        for: 1m
        labels:
          severity: "{{ $labels.severity }}"
